{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71797512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23337706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6e6cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"C:\\Users\\admin\\Downloads\\MCD\\McDonald_s_Reviews.csv\"\n",
    "data = pd.read_csv(dataset_path, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88108fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['review'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38fc83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb0c52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review  \\\n",
      "0      Why does it look like someone spit on my food?...   \n",
      "1      It'd McDonalds. It is what it is as far as the...   \n",
      "2      Made a mobile order got to the speaker and che...   \n",
      "3      My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...   \n",
      "4      I repeat my order 3 times in the drive thru, a...   \n",
      "...                                                  ...   \n",
      "33391                        They treated me very badly.   \n",
      "33392                           The service is very good   \n",
      "33393                         To remove hunger is enough   \n",
      "33394  It's good, but lately it has become very expen...   \n",
      "33395                          they took good care of me   \n",
      "\n",
      "                                        processed_review  \n",
      "0      look like someone spit food normal transaction...  \n",
      "1      itd mcdonalds far food atmosphere go staff mak...  \n",
      "2      made mobile order got speaker checked line mov...  \n",
      "3      mc crispy chicken sandwich customer service qu...  \n",
      "4      repeat order time drive thru still manage mess...  \n",
      "...                                                  ...  \n",
      "33391                                      treated badly  \n",
      "33392                                       service good  \n",
      "33393                               remove hunger enough  \n",
      "33394                       good lately become expensive  \n",
      "33395                                     took good care  \n",
      "\n",
      "[33396 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = clean_text(text)  \n",
    "    tokens = tokenize_text(cleaned_text)  \n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    tokens_without_stopwords = [word for word in tokens if word not in stop_words] \n",
    "    lemmatized_tokens = lemmatize_tokens(tokens_without_stopwords) \n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "\n",
    "data['processed_review'] = data['review'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "print(data[['review', 'processed_review']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c03ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
